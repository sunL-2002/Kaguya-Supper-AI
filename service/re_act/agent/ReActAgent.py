# coding=utf-8
from service.re_act.config.AgentsLLMConfig import AgentsLLM
from service.re_act.execute.ToolExecutor import ToolExecutor
from service.re_act.agent.prompt.sys_prompt import SYS_PROMPT_TEMPLATE
import re


def _parse_output(text: str):
    """è§£æLLMçš„è¾“å‡ºï¼Œæå–Thoughtå’ŒActionã€‚"""
    thought_match = re.search(r"Thought: (.*)", text)
    action_match = re.search(r"Action: (.*)", text)
    thought = thought_match.group(1).strip() if thought_match else None
    print(f"è§£æåå®Œæ•´thought: \n {thought} \n")
    action = action_match.group(1).strip() if action_match else None
    print(f"è§£æåå®Œæ•´action: \n {action} \n")
    return thought, action


def _parse_action(action_text: str):
    """è§£æActionå­—ç¬¦ä¸²ï¼Œæå–å·¥å…·åç§°å’Œè¾“å…¥ã€‚"""
    match = re.match(r"(\w+)\[(.*)\]", action_text)
    if match:
        return match.group(1), match.group(2)
    return None, None


class ReActAgent:
    """
    å¾ªç¯æ‰§è¡Œ, æ¨ç†ä½¿å¾—è¡ŒåŠ¨æ›´å…·ç›®çš„æ€§ï¼Œè€Œè¡ŒåŠ¨åˆ™ä¸ºæ¨ç†æä¾›äº†äº‹å®ä¾æ®
    Thought (æ€è€ƒ) -> Action (è¡ŒåŠ¨) -> Observation (è§‚å¯Ÿ)
    """
    def __init__(self, llm_client: AgentsLLM, tool_executor: ToolExecutor, max_steps: int = 5):
        self.llm_client = llm_client
        self.tool_executor = tool_executor
        self.max_steps = max_steps
        self.history = []

    def run(self, question: str):
        """
        è¿è¡ŒReActæ™ºèƒ½ä½“æ¥å›ç­”ä¸€ä¸ªé—®é¢˜ã€‚
        """
        self.history = []  # æ¯æ¬¡è¿è¡Œæ—¶é‡ç½®å†å²è®°å½•
        current_step = 0

        while current_step < self.max_steps:
            current_step += 1
            print(f"--- ç¬¬ {current_step} æ­¥ ---")

            # 1.æ ¼å¼åŒ–æç¤ºè¯
            tools_desc = self.tool_executor.get_available_tools()
            history_str = "\n".join(self.history)
            react_prompt = SYS_PROMPT_TEMPLATE.get("REACT_PROMPT_TEMPLATE")
            prompt = react_prompt.format(
                tools=tools_desc,
                question=question,
                history=history_str
            )
            print(f"promptå¦‚ä¸‹ï¼š\n {prompt} \n")

            # 2. è°ƒç”¨LLMè¿›è¡Œæ€è€ƒ
            messages = [{"role": "user", "content": prompt}]
            response_text = self.llm_client.think(messages=messages)

            if not response_text:
                print("é”™è¯¯:LLMæœªèƒ½è¿”å›æœ‰æ•ˆå“åº”ã€‚")
                break

            # 3. è§£æLLMçš„è¾“å‡º
            thought, action = _parse_output(response_text)

            if thought:
                print(f"æ€è€ƒ: {thought}")

            if not action:
                print("è­¦å‘Š:æœªèƒ½è§£æå‡ºæœ‰æ•ˆçš„Actionï¼Œæµç¨‹ç»ˆæ­¢ã€‚")
                break

            # 4. æ‰§è¡ŒAction
            if action.startswith("Finish"):
                # å¦‚æœæ˜¯FinishæŒ‡ä»¤ï¼Œæå–æœ€ç»ˆç­”æ¡ˆå¹¶ç»“æŸ
                final_answer = re.match(r"Finish\[(.*)\]", action).group(1)
                print(f"ğŸ‰ æœ€ç»ˆç­”æ¡ˆ: {final_answer}")
                return final_answer

            tool_name, tool_input = _parse_action(action)
            if not tool_name or not tool_input:
                print("...æ— æ•ˆçš„Actionæ ¼å¼...")
                continue

            print(f"ğŸ¬ è¡ŒåŠ¨: {tool_name}[{tool_input}]")

            tool_function = self.tool_executor.get_tool(tool_name)

            if not tool_function:
                observation = f"é”™è¯¯:æœªæ‰¾åˆ°åä¸º '{tool_name}' çš„å·¥å…·ã€‚"
            else:
                observation = tool_function(tool_input)  # è°ƒç”¨çœŸå®å·¥å…·

            print(f"ğŸ‘€ è§‚å¯Ÿ: {observation}")

            # å°†æœ¬è½®çš„Actionå’ŒObservationæ·»åŠ åˆ°å†å²è®°å½•ä¸­
            self.history.append(f"Action: {action}")
            self.history.append(f"Observation: {observation}")

            # å¾ªç¯ç»“æŸ
        print("å·²è¾¾åˆ°æœ€å¤§æ­¥æ•°ï¼Œæµç¨‹ç»ˆæ­¢ã€‚")
        return None
